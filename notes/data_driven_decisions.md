---
title: Data-Driven Decisions
created: '2020-09-27T20:57:29.721Z'
modified: '2021-01-09T19:39:23.871Z'
---

# Data-Driven Decisions

This is my ideal work. I want to be given a question which can be answered using some combination of domain knowledge and statistical estimates derived from data. My job would then be to design a system to answer this question. This involves two tasks:

- Determining what the design of the system should be. What are the inputs, i.e. what data sources are available, and what data sources are most relevant? And what outputs do we want? What are we predicting, forecasting, modeling, etc?
- Building a functional protype in a high-level language like Python. Python is optimal because all necessary components in the system can be developed in Python, including data ingestion/processing/formatting; model implementation, fitting, hyperparameter optimization; formatting of model results; statistical, numerical and algorithmic methods necessary to format the input data or create the outputs; and any other code necessary to glue everything else together and/or automate it.

The problem of automation is particularly important. A natural inference is that this kind of work, in which we design systems to give answers to questions/predictions automatically or quasi-automatically, can and will itself be automated, thus making the particular skills necessary to do this work obsolete, like the skills necessary to build horse buggies in the wake of the automobile. This may very well be true of the second point above, the part of the work concerned with developing the code for the system. But this ignores the first point, in which we must decide what the structure of the system itself will be, and how it will function. By structure I don't mean the number of hidden layers in the neural network or the hyperparameter optimization framework. I'm referring to the meta-decisions, decisions driven by an understanding of what kind of answers the stakeholders want and how we could go about answering them. This must, in some sense, involve decision-making which cannot be automated, because all of my knowledge and experience as a human must be brought to bare to solve it. 

For example, let's say that your CEO wants to be able to forecast the productivity of the Pilbara iron ore mines in Australia _in real time_. In the mythical automated future, you simply turn to your Data-omatic 3000™ and type in

`Make a system to forecast the productivity of Pilbara Iron ore mines`

and boom, job done. Who needs a dumb-ol' human anyway. But if you don't have a Data-omatic, then your stuck with a data scientist/engineer/product manager/whatever. Me. And he's got a lot of work to do. He needs to find out what data is available to answer the question, and how to use it to do so. He decides, for example, that one potential solution is to buy access to daily satellite imagery of the mine and analyze the ore piles to see how much has been extracted. Hopefully he can build a model accurate enough to estimate the production rate of the mine daily. But maybe the amount of ore extracted isn't the only relevant factor. Maybe the ore needs to be refined before its shipped from the mine to a port from where it will then be shipped off to steel plants. How do we estimate refining activity if, for example, the refined material is stored in covered containers? "Maybe," the poor organic stand-in for a Data-omatic opines, "we can count the number of cars in the parking lot of the refinery to estimate production rates?" But then the data scientist realizes that all of the refined material must be shipped out by train from the refinery, and he could simply build a system to count the number of car-loads of refined ore leaving the factory. 

This is an example of the kinds of decisions which are interesting to me. These decisions involve data science, machine learning, and statistics in that these decisions determine how best to use these tools. But machine learning/numerical computation/algorithms/etc.: these are all _tools_ wielded by the data scientist/engineer/product manager/whatever to solve the problem. Automation of these tools doesn't make him obselete: it makes him more efficient. In fact, he is continually automating all aspects of his workflow with glue code written in `Insert Scripting Language Here` so that he can spend more time deciding how to build systems that answer important questions. 

Although he is forever abstracting himself from the underlying computation, he must still understand what the technology _actually does_, because if he doesn't then he cannot know its limitations. Deciding how to build solutions - which is what is job is - requires knowing what the solution space looks like. And this space is clearly constrained by the capabilities of the tools at his disposal. You don't want a person who doesn't understand the technology and the math/stats which underpins it deciding how to build one of these systems because they are the ones who geniunely think that machine learning systems work like the Data-omatic. They don't understand which techniques are best suited for which problems, and they don't know how to translate a question, like the mine productivity question, into a problem which can be solved algorithmically. __My value-added is that I can translate a difficult question posed by a human into a problem which can be solved algorithmically, and design a system which can do so__. It may not be World-class Elite Hacker Rockstar Code, but it will be good enough for our Russian Elite Hacker Coding Superstars™ to translate into production-grade software. But I don't give a `Redacted` about that because I just send them my Python code and pay them $10.50 an hour and they send me a C++ repo a week later. That's not my job.
