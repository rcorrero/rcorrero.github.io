---
title: Data-Driven Decisions
created: '2020-09-27T20:57:29.721Z'
modified: '2021-08-23T18:00:53.035Z'
---

# Data-Driven Decisions

This is my ideal work. I want to be given a question which can be answered using some combination of domain knowledge and statistical estimates derived from data. My job would then be to design a system to answer this question. This involves two tasks:

- Determining what the design of the system should be. What are the covariates, i.e., what data sources are available, and what data sources are most relevant? And what are the outcomes, that is, what are we predicting, forecasting, modeling, etc? How do we process the covariates to extract relevant information from them?
- Building a functional protype in a high-level language like Python. Python is optimal because all necessary components in the system can be developed in Python, including data ingestion/processing/formatting; model implementation, fitting, hyperparameter optimization; formatting of model results; statistical, numerical and algorithmic methods necessary to format the input data or create the outputs; and any other code necessary to glue everything else together and/or automate it. Importantly, Python is also a great environment for [EDA](https://en.wikipedia.org/wiki/Exploratory_data_analysis), and the statistical inference packages are, in my opinion, just as good as those in R.

## Can automation be automated?

The problem of automation is particularly important. A natural inference is that this kind of work, in which we design systems to give answers to questions/predictions automatically or quasi-automatically, can and will itself be automated, thus making the skills necessary to do this work obsolete, like the skills necessary to build horse buggies in the wake of the automobile. This may very well be true of the second point above, the part of the work concerned with developing the code for the system. But this ignores the first point, in which we must decide what the structure of the system itself will be, and how it will function. By structure I don't mean the number of hidden layers in the neural network or the hyperparameter optimization framework. I'm referring to the meta-decisions, decisions driven by an understanding of what kind of answers the stakeholders want and how we could go about answering them without violating key assumptions. This must, in some sense, involve decision-making which cannot be automated, because all my knowledge and experience as a human must be brought to bear to solve it. 

For example, let's say that your CEO wants to be able to forecast the productivity of the Pilbara iron ore mines in Australia _in real time_. In the mythical automated future, you simply turn to your Dataomatic 3000™ and type in

`Make a system to forecast the productivity of Pilbara Iron ore mines`

and boom, job done. Who needs a dumb-ol' human anyway? But if you don't have a Dataomatic, then you’re stuck with me. And I've got a lot of work to do. I need to find out what data is available to answer the question, and how to use it to do so. I decide, for example, that one potential solution is to buy access to daily satellite imagery of the mines and analyze the ore piles to see how much has been extracted. Hopefully I can build a model accurate enough to estimate the production rate of the mines daily. But maybe the quantity of ore extracted isn't the only relevant factor. Maybe the ore needs to be refined before its shipped from the mine to a port from where it will then be shipped off to steel plants. How do we estimate refining activity if, for example, the refined material is stored in covered containers? "Maybe," the poor organic stand-in for a Dataomatic opines, "we can count the number of cars in the parking lot of the refinery to estimate production rates?" But then I realize that all of the refined material must be shipped out by train from the refinery, and I could simply build a system to count the number of carloads of refined ore leaving the factory. 

So, I look for rail carriages of iron ore in the satellite imagery, and noticing that the carriages are open-topped, I extract the spectral reflectance curves associated with the iron ore contained within them and begin analyzing the data. I plot the reflectance values for each channel separately and compare them to a [benchmark spectrum](https://crustal.usgs.gov/speclab/QueryAll07a.php?quick_filter=iron) for iron ore. I notice that, not only is the spectrum associated with iron ore relatively unique, but by comparing the spectra of the rail carriages with benchmark spectra, I may be able to estimate the quality of the ore produced, and hence its value. From there I begin modeling the data, progressively incorporating more complex features such as spatial information, using statistical modeling both for inference — understanding the data — and for prediction — testing whether a predictive model can make sense of the data.

This is an example of the kinds of decisions which are interesting to me. These decisions involve machine learning in that these decisions determine how best to use those tools. But machine learning/numerical computation/algorithms/etc.: these are all _tools_ wielded by me to solve the problem. Automation of these tools doesn't make me obsolete: it makes me more efficient. In fact, I am continually automating all aspects of my workflow with glue code written in `Insert Scripting Language Here` so that I can spend more time understanding the data. 

Although I am forever abstracting myself from the underlying computation, I must still understand what the technology _actually does_, because otherwise I cannot know its limitations. Deciding how to build solutions - which is what my job is - requires knowing what the solution space looks like. And this space is clearly constrained by the capabilities of the tools at my disposal. You don't want a person who doesn't understand the technology and the math/stats which underpins it deciding how to build one of these systems because they are the ones who genuinely think that machine learning systems work like the Dataomatic. They don't understand which techniques are best suited for which problems, and they don't know how to translate a question, like the mine productivity question, into a problem which can be solved algorithmically. __My value-added is that I can translate a difficult question posed by a human into a problem which can be solved algorithmically and design a system which can do so without violating the assumptions of the stakeholders__.

## Justification

In their haste to optimize their algorithms within the [common task framework](https://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf), machine learning engineers often forget that there is more to developing a predictive model than writing good code and maximizing the target performance metric. If I've been tasked with the development of a predictive model, I must not only deliver _a predictive model_, but also be able to justify _why I chose the model I chose_. 

Justification requires the careful use of statistical inference and knowledge of the covariates employed by the model, as well as intimate knowledge of the way in which the model uses them. Without this, no guarantees for future performance may be given except those based on out-of-sample performance. But when the models I'm building are going to be used to make mission-critical decisions, good performance on the evaluation data is rarely sufficient to prove that the model is ready for deployment. 

This is where the __...without violating the assumptions of the stakeholders__ part of my value-added comes into play. I must be able to prove that the model does not violate the stakeholders’ assumptions. Indeed, the choice of the model architecture used must be driven by an understanding of the needs of the stakeholders. If the model is making life and death decisions, then it should certainly be interpretable: if the model makes a terrible mistake, then we must be able to understand _why_. This isn’t possible with a black box model.

