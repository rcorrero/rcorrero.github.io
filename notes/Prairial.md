---
title: Prairial
created: '2020-06-06T18:19:30.725Z'
modified: '2020-07-25T23:50:01.238Z'
---

# Prairial

I cannot pretend to know precisely what motivates me to begin in this endeavor except that it is based in emotion: a notion of beauty, meaning, and power, and all else that motivates anyone. The deep ML models which are currently being appropriated for use in myriad supposed usecases by an ungodly number of startups are based on elegant theory combined with impressive engineering, and this confluence of idea and action is in some sense exciting to me personally. But of course the hype surrounding deep models and ML in general is a cloud of noise through which the beauty of the ideas themselves can barely penetrate. And these models, as they are, are by and for capital – hence it's only natural that their implementation is driven solely by the desires of those who see money in it. Without the profit motive the modern ML ecosystem wouldn't exist, and it's unlikely that I would have ever heard about the models outside of my university. But these systems may be used for other purposes besides the creation of profit for tech companies, and given enough effort and creativity, new models may be designed to extend the human's capacity to make beautiful, meaningful things. 

The desire to develop _anything at all_ motivates me at base, but the problem with tools is that they're only valuable in relation to the problem which they solve. Hence it's difficult to do anything meaningful with them without a specific problem which they are intended to rectify. For myself, I've spent years dreaming of problems to solve, cycling through a litany of imagined usecases with supposed possibilities for economic profit. But of course the individual, without the backing of the structures which govern the flow and application of capital in the world, by definition lacks access to both the information necessary to discover good and novel usecases and the resources necessary to build out solutions in these niches. What I've come to realize – something that should've been obvious to me all the while – is that this game may only really be played and won from within the system. Only those sitting on top of the full force and might of the tech corporation can really win, with a few sucessful startups circling around the giants like pilot fish.

But the profit motive, for me anyway, was always a pretext for action. _Any motive at all_ is all I need, because what I really want to do is to create meaningful things. It makes sense, therefore, to do away with the pretext of the profit motive, a motive which contorts and constrains the world of possibility until beauty and meaning is almost completely drained from any endeavor (except the meaning which one finds in ensuring his or her continued existence), and to instead elevate that which I'm truly after (meaning) to its rightful place as the prime motivator. Rather than creating money the machine will create meaning and beauty.

What things are meaningful? Once again I can't pretend to truly know the answer, but the key properties which any meaningful object must possess are
- surprisingness/novelty
- ingenuity
- interpretability
- uninterpretability 
- complexity

It seems possible to design models to optimize over these traits. In this sense the model may be thought of as a machine for the production of meaning, or atleast objects which exhibit many of the traits correlated with it.


## Notes
_Deep Learning – Goodfellow et. al._
1. The importance of priors – when learning the coloring of the checkerboard, the assumption of smoothness would require a sample including points from each grid square. If instead our prior incorporates knowledge of the pattern itself, only a handful of samples are needed to deduce the correct coloring.
2. The core idea of deep learning is that we assume that the data was generated by the composition of factors
3. In many applications the distribution of interest is highly constrained within the domain of interest. Imagine the possible arrangement of pixel colors and intensities within a 1024 by 1024 grid – the space of human faces occupies a high–dimensional manifold within this space.


An interesting lead is found on page 692:
_"The GAN learning problem can also be simplified by breaking the generation process into many levels of detail. It is possible to train conditional GANs (Mirza and Osindero, 2014) that learn to sample from a distribution p(x | y) rather than simply sampling from a marginal distribution p(x). Denton et al. (2015) showed that a series of conditional GANs can be trained to first generate a very low-resolution version of an image, then incrementally add details to the image. This technique is called the LAPGAN model, due to the use of a Laplacian pyramid to generate the images containing varying levels of detail. LAPGAN generators are able to fool not only discriminator networks but also human observers, with experimental subjects identifying up to 40 percent of the outputs of the network as being real data. See figure 20.7 for examples of images generated by a LAPGAN generator."_
