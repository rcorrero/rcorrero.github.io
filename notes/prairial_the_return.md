---
title: Prairial | The Return
created: '2020-07-21T20:27:36.878Z'
modified: '2020-07-21T20:38:55.350Z'
---

# Prairial | The Return

I want the challenge of designing a learning problem, in an ML context, which when solved yields a model capable of understanding some aspects of the beautiful abstract correspondance between language and the imagery which it evokes. The trained model – the product of the learning process – should understand (some of) the complexity of language and the visuals to which it's associated. This is a question of hierarchies and complex functions, and is so underconstrained that imagination alone will save it from arbitrariness. If the machine can capture just one sense of correspondence between language and imagery, and the emotional context which the imagery occupies, then it will have learned something so beautiful and meaningful that itself must be said to be meaningful. 

What I imagine is a machine which, when given a sentence, a paragraph, a book-length piece of text, etc. generates an image corresponding to the key abstract properties of the text. The correspondence is clearly underdetermined, but it must satisfy the following constraint: it must encode some notion of meaning in the array of pixel values which it returns. Somewhere within the visual cortex, or some other part of the brain, elements of much of the things we see in our lives are encoded. When speaking, reading, thinking of something interesting we – or at least I – cannot help but return to the past, as encoded in this imagery. There is clearly a complex correspondence between thought and visual memory, and that is what I'm interested in. 

When I think of 
