---
title: Aprilis
created: '2020-04-08T15:02:16.098Z'
modified: '2020-05-21T17:26:43.490Z'
---

# Aprilis

## Motivation
"It is precisely when we recognise the same amount of structure in a wide variety of interesting examples that the abstract approach comes into its own."
––– Armstrong, [_Groups and Symmetry_](https://link.springer.com/book/10.1007/978-1-4757-4034-9)

In the course of designing solutions to machine learning problems certain approaches show up, often in disparate and unlikely places. The number of useful representations and methods for utilizing them is functionally infinite, and the number of dimensions along which machine learning systems may vary is vast. Yet, some schema seem implausibly well-suited to tasks which seemingly share no structure besides their basic formulation as a learning problem. This is an exploration of one such schema.

## Goals
- Development of a functional framework for creating well-founded statistical models using deep models as inputs. In particular, using the transfer learning method from [this paper](https://science.sciencemag.org/content/sci/353/6301/790.full.pdf?casa_token=IGFOJXgxvdYAAAAA:TSJ7AHkOLDHdUlyEDoHBwwXvdBKQJRost_Qp5YxaAHIUAeOE8enNIUybJ_zpf3mKPTkIWor-v6JtlA), use pretrained models to generate features based on input satellite imagery. Combine these deep features with shallow features which are application-specific, fit a (regularized) regression model over both types of features to predict some dependent variable of interest, i.e. land-value, etc. Using a pretrained model as a base on which to build domain-specific neural classifiers requires adding neural layers and the associated modifications – learn how to do this.

- This framework should encapsulate the structural similarities between the model herein developed and the model of [Germinal](https://projects.richardcorrero.com/notes/germinal.html).

## Avenues of Inquiry
- The domain-agnostic technicalities of learning with pre-trained neural models. Specifically, how to modify models in the most natural way through the addition and removal of neural layers.
- The design of meaningful transfer-learning approaches to prediction in the same vein as [this paper](https://science.sciencemag.org/content/sci/353/6301/790.full.pdf?casa_token=IGFOJXgxvdYAAAAA:TSJ7AHkOLDHdUlyEDoHBwwXvdBKQJRost_Qp5YxaAHIUAeOE8enNIUybJ_zpf3mKPTkIWor-v6JtlA).
- Using features generated by deep models as predictors in regularized linear models such as ordinary least squares or logistic regression.
- The combination of low-dimensional features such as indicies and summary statistics with "deep" features. 
- Processing raw satellite imagery such that it may be used in a neural architecture.

## Finding a Problem
- I called the media relations office at the Port of Los Angeles on April 22, 2020 to see if they'd give me a running count of the number of TEUs which had moved through the port so far in the month of April. I was told that they did not have that number, and that to get the number I would have to wait until it was published on their website, on or after the 15th of May. I was told that "...there is no running count [of TEUs]." I was further told that other ports were similarly unwilling to release unofficial counts, only releasing official numbers weeks after the end of the reporting period. This suggests an opportunity for information arbitrage. If we can build a model which can estimate this number to within an acceptable confidence interval, then we may determine the amount of goods moving through the world's largest shipping ports – intermodal terminals such as the Port of Los Angeles – weeks before that quantity is made public by the Port itself. Knowing the quantity of exports and imports flowing through such ports before others likely presents a competitive advantage to any organization attempting to accurately predict the future trajectory of the global economy and its constituents. 

## 2020-05-16
### Two-part creation
In the course of generating useful signals we need to build a model by which the signals themselves may be tested. We therefore have two key tasks in novel signal development:
1. Build signal extraction infrastructure
2. Fit a model to the system of interest to test the signifigance of the signal

There are thus two major 

## References
- [Combining satellite imagery and machine learning to predict poverty](https://science.sciencemag.org/content/sci/suppl/2016/08/19/353.6301.790.DC1/Jean.SM.pdf)
